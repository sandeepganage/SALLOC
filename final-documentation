As part of GSoC 2017, I implemented an arena based memory allocator in CUDA.
It supports the vector container on GPUs.
The following functionalities are supported by this vector Container.
* push_back() 
* pop_back() 
* getIndex()

The memory allocator supports multiple vectors. push_back() and pop_back can be performed on multiple vectors concurrently.

Implementation Procedure/Details :

The memory allocation should be thread safe.
To ensure thread safe behaviour of the memory operation, we pre-allocate a large chunk of memory on the GPU from CPU using the cudaMalloc() API. This pre-allocated space is called 'arena'.

The arena is organised as an aray of a said 'capacity', divided into chunks.
The capacity is user specified.

A Chunk contains an array of 'CHUNK_SIZE' of type '<T>'. Other fields in a chunk include next, prev pointers to other chunks in the same arena.

A Chunk can only contain elements of a single vector. A vector however span across multiple chunks. 

The set of all chunks that comprise a vector are organised as a doubly linked list.

Each chunk has a field 'nextFreeValue'  to track of number of elements in the chunk, initialised to zero.

The 'nextFreeChunk_d' field holds the offset to the next free chunk in the arena.






************************

push_back()

void push_back( <T>*, <T> element){

}

The push_back() operation pushes a scalar to a location in a chunk.

A shared variable 'nextFreeValue', keeps track of the next free location inside a chunk where the insertion can take place. 'nextFreeValue' is incremented using atomicAdd to avoid data races.

Similarly, 'nextFreeChunk_d' is used to keep track of whether the capacity of the arena is exhausted or not.

If a chunk gets full, but there are other chunks available, then a new chunk is exposed to the user program, from the arena, by incrementing the value of 'chunkCount' atomically and returning the address of the new chunk.

More than one vectors can be allocated and maintained on the arena. Each new vector starts at a new chunk.

Outside the arena, on the GPU, the address of the starting chunk of each vector is stored, as meta-data. These offset addresses are visible to all threads. 

When push_back() is to be performed on a specified vector, each thread first reads-off the address of the chunk for the vector and then proceeds to push_back() into
the correct chunk.

In cases when a vector spans across multiple chunks, a fully free (new) chunk is requested each time a vector spills to a new chunk. This is done to ensure that a chunk contains the elements of one vector alone. This helps in preventing the data of different vectors from getting mixed up.

 A vector can be traversed by starting at the specified address offset and going over the chunks following the links between chunks.

In case a new chunk is to added to the vector, a single thread aquires a lock on the last chunk of the  linked list, increments 'nextFreeChunk_d' and adds the new chunk to the linked list.

Only the thread that succesfully perform the 'push_back' operation update the value of 'nextFreeValue'  within the chunk. This disallows spurious updation  of the concerned field  thereby preventing sideeffects.


******************************

<T> pop_back(<T*>){
	
}

Each thread starts at the head node of the vector and traverses the linked list of chunks for that vector to reach the last chunk, where pop_back has to be performed.

Once the chunk is identified, we atomically decrement 'nextFreeValue' and return the value being popped .

If the current chunk becomes empty, one thread acquires a lock on the empty chunk and delinks the last chunk by setting the next pointer of parent chunk to NULL, and the previous pointer of the empty chunk to NULL.

If the deleted chunk happesn to be the last exposed chunk of the arena, 'nextFreeChunk_d' is decremented by 1 to reclaim the recently freed space.

Only the thread that succesfully perform the 'pop_back' operation update the value of 'nextFreeValue'  within the chunk.This disallows spurious updation  of the concerned field  thereby preventing sideeffects.


*************************************

int getIndex(<T*>,int){
	
}

It maps the index of a vector to the index of the arena.

Each thread starts at the head chunk of the vector and interates over the list of chunks until the intended index of the vector is found, or till the end.

Upon succesful identification of the required chunk, we compute the coressponding index of the arena as follows 
 			
(address_of_current_chunk - base_address_of_arena)*CHUNK_SIZE + vectorIndex % CHUNK_SIZE

The index so computed is returned.


***************************************

<T*> createVector(){
	
}

This is a host API, for allocating multiple vectors on the arena.

A call to this API does the following
1. returns the address of the next free chunk on the arena 
2. increments the value of 'nextFreeChunk_d' by 1 to reserve a chunk for itself.

As a result of the above, the API call sets aside 1 chunk for the newly created vector, however it reserves exaclty one chunk (of size CHUNK_SIZE) in the arena, irrespective of the requested size.

****************************************



