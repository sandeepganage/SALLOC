
For the  GSoC 2017 project, "Smart Data Structures in CUDA", I implemented an arena based memory allocator in CUDA.
It has support for vector container on GPUs.
	
The following operations are supported on this vector container on the arena.
	* push_back() 
	* pop_back() 
        * getIndex()
	* vecSize()

In addition, the memory allocator supports allocation of multiple vectors. 
push_back() and pop_back() can be performed on multiple vectors concurrently.

Implementation Details :
-----------------------------------

1. The memory allocator should ensure that if multiple threads are requesting memory, the allocation is thread safe. To ensure thread safe behavior of the memory operations, we pre-allocate a large chunk of memory on the device (GPU) from the host (CPU) using the cudaMalloc() API. This pre-allocated space is called 'arena'.

2. The arena is organized as an array of a said 'capacity', divided into chunks.
The capacity is user specified.

3. A 'chunk' contains an array of 'CHUNK_SIZE' of type 'T'. The type 'T' is also user specified.
Other fields in a chunk include *next, *prev, that are pointers to other chunks in the same arena.

4. A chunk can only contain elements of a single vector. A vector, however, spans across multiple chunks. 

5. The set of all chunks that comprise a vector are organized as a doubly linked list.

6. Each chunk has a field 'nextFreeValue', initialized to zero, to keep track of the number of elements in the chunk.

7. The 'nextFreeChunk_d' field holds the offset to the next free chunk in the arena.


The various operations supported on the vector container on the arena are discussed below:

I. push_back()
--------------

  void push_back( T*, T element);

The push_back() operation pushes a scalar to a location in a chunk in the arena.

A shared variable 'nextFreeValue', keeps track of the next free location inside a chunk where the insertion can take place. 'nextFreeValue' is incremented after every insertion using atomicAdd() to avoid data races.

Similarly, 'nextFreeChunk_d' is used to keep track of whether the capacity of the arena is exhausted or not.

If a chunk gets full, but there are other chunks available, then a new chunk is exposed to the user program, from the arena, by incrementing the value of 'nextFreeChunk_d' atomically and returning the address of the new chunk.

More than one vector can be allocated and maintained on the arena. Each new vector starts at a new chunk.

Outside the arena, on the GPU, the address of the starting chunk of each vector is stored, as meta-data. These offset addresses are visible to all threads. 

When push_back() is to be performed on a specified vector, each thread first reads-off the address of the chunk for the vector and then proceeds to push_back() into the correct chunk.

In cases when a vector spans across multiple chunks, a fully free (new) chunk is requested each time a vector spills to a new chunk. This is done to ensure that a chunk contains the elements of one vector alone. This helps in preventing the data of different vectors from getting mixed up.

A vector can be traversed by starting at the specified address offset and going over the chunks following the links between chunks.

When a  new chunk is to be added to a vector, a single thread acquires a lock on the last chunk of the linked list, increments 'nextFreeChunk_d' and adds the new chunk to the linked list.

Only the threads that successfully perform the 'push_back' operation update the value of 'nextFreeValue'  within the chunk. This disallows spurious updation  of the concerned field, thereby preventing side-effects.


II. pop_back()
---------------

  T pop_back(T*);

Each thread starts at the head node of the vector and traverses the linked list of chunks for that vector to reach the last chunk, where pop_back() has to be performed.

Once the chunk is identified, we atomically decrement 'nextFreeValue' and return the popped value.

If the current chunk becomes empty, one thread acquires a lock on the empty chunk and delinks the chunk by setting the *next pointer of parent chunk nd the *prev pointer of the empty chunk to NULL.

If the deleted chunk happens to be the last exposed chunk of the arena, 'nextFreeChunk_d' is decremented by 1 to reclaim the recently freed space.

Only the threads that successfully perform the 'pop_back' operation update the value of 'nextFreeValue'  within the chunk. This disallows spurious updation  of the concerned field, thereby preventing side-effects.


III. getIndex()
---------------
	
  int getIndex(T*,int);

This method maps the index of a vector to a corresponding index of the arena.

Each thread starts at the head chunk of the vector and iterates over the list of chunks until the intended index of the vector is found, or till the end.

Upon successful identification of the chunk containing the vector's index, we compute the corresponding index of the arena as : 

	(address_of_current_chunk - base_address_of_arena)*CHUNK_SIZE + vectorIndex % CHUNK_SIZE

The index so computed is returned.

IV. vecSize()
--------------

  int vecSize(T*);

This method returns the size of the vector.



V. createVector() 
------------------

  T* createVector();

This is a host API for allocating multiple vectors on the arena.

A call to this API does the following:
  i. Returns the address of the next free chunk on the arena 
 ii. Increments the value of 'nextFreeChunk_d' by 1 to reserve a chunk for itself.

As a result of the above, the API call sets aside 1 chunk for the newly created vector.
