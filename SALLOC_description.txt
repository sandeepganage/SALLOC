
For the  GSoC 2017 project, "Smart Data Structures in CUDA", I implemented an arena based memory allocator in CUDA.
It has support for vector container on GPUs.
	The following operations are supported on this vector container in the arena.
	* push_back() 
	* pop_back() 
* getIndex()

	In addition, the memory allocator supports allocation of multiple vectors. push_back() and pop_back() can be performed on multiple vectors concurrently.

	Implementation Procedure/Details :

	1. The memory allocator should ensure that if multiple threads are requesting memory, the allocation is thread safe. To ensure thread safe behavior of the memory operations, we pre-allocate a large chunk of memory on the device (GPU) from the host (CPU) using the cudaMalloc() API. This pre-allocated space is called 'arena'.

	2. The arena is organized as an array of a said 'capacity', divided into chunks.
	The capacity is user specified.

	3. A 'chunk' contains an array of 'CHUNK_SIZE' of type '<T>'. 
	Other fields in a chunk include *next, *prev, that are pointers to other chunks in the same arena.

	4. A chunk can only contain elements of a single vector. A vector however spans across multiple chunks. 

	5. The set of all chunks that comprise a vector are organized as a doubly linked list.

	6. Each chunk has a field 'nextFreeValue', initialized to zero, to keep track of the number of elements in the chunk.

	7. The 'nextFreeChunk_d' field holds the offset to the next free chunk in the arena.

	The various operations supported on the vector container are discussed below:

I. push_back()
--------------
	void push_back( <T>*, <T> element);

	The push_back() operation pushes a scalar to a location in a chunk in the arena.

	A shared variable 'nextFreeValue', keeps track of the next free location inside a chunk where the insertion can take place. 'nextFreeValue' is incremented after every insertion using atomicAdd to avoid data races.

	Similarly, 'nextFreeChunk_d' is used to keep track of whether the capacity of the arena is exhausted or not.

	If a chunk gets full, but there are other chunks available, then a new chunk is exposed to the user program, from the arena, by incrementing the value of 'nextFreeChunk_d' atomically and returning the address of the new chunk.

	More than one vector can be allocated and maintained on the arena. Each new vector starts at a new chunk.

	Outside the arena, on the GPU, the address of the starting chunk of each vector is stored, as meta-data. These offset addresses are visible to all threads. 

	When push_back() is to be performed on a specified vector, each thread first reads-off the address of the chunk for the vector and then proceeds to push_back() into the correct chunk.

	In cases when a vector spans across multiple chunks, a fully free (new) chunk is requested each time a vector spills to a new chunk. This is done to ensure that a chunk contains the elements of one vector alone. This helps in preventing the data of different vectors from getting mixed up.

	A vector can be traversed by starting at the specified address offset and going over the chunks following the links between chunks.

	When a  new chunk is to be added to the vector, a single thread acquires a lock on the last chunk of the  linked list, increments 'nextFreeChunk_d' and adds the new chunk to the linked list.

	Only the threads that successfully perform the 'push_back' operation update the value of 'nextFreeValue'  within the chunk. This disallows spurious updation  of the concerned field  thereby preventing side-effects.


II. pop_back()
---------------
	<T> pop_back(<T*>);

	Each thread starts at the head node of the vector and traverses the linked list of chunks for that vector to reach the last chunk, where pop_back() has to be performed.

	Once the chunk is identified, we atomically decrement 'nextFreeValue' and return the value being popped .

	If the current chunk becomes empty, one thread acquires a lock on the empty chunk and delinks the chunk by setting the *next pointer of parent chunk nd the *prev pointer of the empty chunk to NULL.

	If the deleted chunk happens to be the last exposed chunk of the arena, 'nextFreeChunk_d' is decremented by 1 to reclaim the recently freed space.

	Only the thread that successfully perform the 'pop_back' operation update the value of 'nextFreeValue'  within the chunk. This disallows spurious updation  of the concerned field  thereby preventing side-effects.

III. getIndex()
---------------
	int getIndex(<T*>,int);

	This method maps the index of a vector to a corresponding index of the arena.

	Each thread starts at the head chunk of the vector and iterates over the list of chunks until the intended index of the vector is found, or till the end.

	Upon successful identification of the chunk containing the vector's index, we compute the corresponding index of the arena as follows 

	(address_of_current_chunk - base_address_of_arena)*CHUNK_SIZE + vectorIndex % CHUNK_SIZE

	The index so computed is returned.

IV. vecSize()
--------------

	int vecSize(T*);

	This method returns the size of the vector.



V. createVector() 
------------------
	<T*> createVector();

	This is a host API, for allocating multiple vectors on the arena.

	A call to this API does the following
	1. Returns the address of the next free chunk on the arena 
	2. Increments the value of 'nextFreeChunk_d' by 1 to reserve a chunk for itself.

	As a result of the above, the API call sets aside 1 chunk for the newly created vector, however it reserves exactly one chunk (of size CHUNK_SIZE) in the arena, irrespective of the requested size.
